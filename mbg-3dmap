# Copyright (C) 2010 Anand Patil
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from optparse import OptionParser
import os, sys, time, imp, datetime

# Create option parser
req_doc = """

mbg-3dmap  Copyright (C) 2010 Anand Patil
This program comes with ABSOLUTELY NO WARRANTY.
This is free software, and you are welcome to redistribute it under certain conditions.
See <http://www.gnu.org/licenses/> for the terms of the license.


  module                The module from which maps are to be generated.
  database-file         The name of the database file produced by the mcmc.
  burn                  The number of initial MCMC iterations to discard. 
                        You must provide this argument.
  mask                  An ascii file with some pixels MISSING. Maps will 
                        be generated in ascii files with identical masks.
"""
p = OptionParser('usage: %prog module database-file burn mask [options]' + req_doc)

p.add_option('-n','--n-bins',help='The number of bins to use when creating histograms. Defaults to 100.',dest='n_bins',type='int')
p.add_option('-b','--bufsize',help='The size of the buffer to use, in pixels. Use 0 if raster-thin=1. Defaults to 0.',dest='bufsize',type='int')
p.add_option('-q','--quantiles',help="The quantile maps to generate. Should be in the form '0.05 0.25 0.5 0.75 0.95', and the inverted commas are important! Defaults to '0.05 0.25 0.5 0.75 0.95'",dest='quantile_list')
p.add_option('-r','--raster-thin',help='The raster will be kriged at this level of degradation, then regridded. Set to 1 for final maps, ~10 for mild curiosity. Defaults to 1.',dest='raster_thin',type='int')
p.add_option('-t','--thin',help='How much to thin the MCMC trace. Defaults to 10.',dest='thin',type='int')
p.add_option('-i','--iter',help='The total number of samples to use in generating the map. Defaults to 20000',dest='total',type='int')
p.add_option('-p','--raster-path',help="The path to the covariate rasters. Defaults to the current working directory.",dest='raster_path')
p.add_option('-y','--year',help='The decimal year at which the map should be produced. Required for space-time models.',dest='year',type='float')
p.add_option('-d','--ignore-npd',help='Whether to discard and continue past non-positive-definite iterations.',dest='continue_past_npd',type='int')

p.set_defaults(n_bins=100)
p.set_defaults(raster_path='.')
p.set_defaults(raster_thin=1)
p.set_defaults(thin=50)
p.set_defaults(total=50000)
p.set_defaults(bufsize=0)
p.set_defaults(year=None)
p.set_defaults(continue_past_npd=0)
p.set_defaults(quantile_list='0.05 0.25 0.5 0.75 0.95')

o, args = p.parse_args()

from generic_mbg import *
check_args(args, 4)

o.module, o.hf_name, o.burn, o.mask_name = args
o.burn = int(o.burn)


exec(delayed_import_str)

# Load up given module and load its relevant contents
M, hf, mod, mod_name = reload_model(o.module, o.hf_name)
nuggets, obs_labels = get_nuggets_and_obs(mod, mod_name, M)    
extra_reduce_fns, extra_finalize = get_reduce_finalize(mod)

# Parse quantiles
q=parse_quantiles(o)


# Create predictive locations
unmasked, x = get_mask_t(o, hf)

# Restore model
bins = np.linspace(0,1,o.n_bins)

# Load covariates
covariate_dict = get_covariate_dict(M, o, unmasked)
            
# Create utility fns
def binfn(arr,n_bins=o.n_bins):
    return np.array(arr*n_bins,dtype=int)

hsr = histogram_reduce(bins, binfn)

def finalize(prod, n):
    # Use unmasked here...
    n_ = float(n)
    mean = np.zeros(unmasked.shape)
    mean[unmasked] = prod[mean_reduce] / n_
    
    density_field = np.zeros(unmasked.shape+(o.n_bins,))
    for i in xrange(o.n_bins):
        density_field[:,:,i][unmasked] = prod[hsr][:,i]/n_
    
    # from IPython.Debugger import Pdb
    # Pdb(color_scheme='LightBG').set_trace() 
    
    return {'density_field': density_field, 'mean': mean}

reduce_fns = [mean_reduce, hsr]

# Create rasters
t_start = time.time()

products = hdf5_to_samps(M,x,nuggets,o.burn,o.thin,o.total,reduce_fns, mod.map_postproc, covariate_dict, finalize, o.continue_past_npd)
print '\nMaps produced in %f seconds\n'%(time.time() - t_start)

# Write out
init_output_dir(o, '3dmap')
lon,lat,mask_data,mask_type = import_raster(o.mask_name, path=o.raster_path)
bbox = [lon.min(), lat.min(), lon.max(), lat.max()]
for f in mp:
    output_hdf5 = tb.openFile('3dmap-%s-data.hdf5'%f.__name__,'w')
    output_hdf5.createArray('/','mean',products[f]['mean'])
    output_hdf5.createArray('/','bbox',bbox)
    output_hdf5.createTable('/','input_csv',hf.root.input_csv[:])
    output_hdf5.createCArray('/','density_field',tb.FloatAtom(),unmasked.shape+(o.n_bins,),filters=tb.Filters(complevel=1, complib='zlib'))
    output_hdf5.createArray('/','unmasked',unmasked)
    output_hdf5.root.density_field[:] = products[f]['density_field'][:]
    output_hdf5.close()